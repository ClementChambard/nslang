#include io.nsh
#include file_lexer.nsh
#include lexer.nsh
#include mem.nsh
#include ident_info.nsh
#include diags.nsh

fn file_lexer_create(filename: i8*, the_lexer: void*) -> FileLexer* {
    let f: OpenedFile*;
    f = opened_file_find(filename);
    if (f == nullptr) {
        f = opened_file_open(filename);
    }
    let self: FileLexer*;
    self = malloc(sizeof(FileLexer));
    self->f = f;
    self->pos = 0;
    self->the_lexer = the_lexer;
    return self;
}

fn file_lexer_construct_token(self: FileLexer*, token: Token*, end_pos: i64, ty: Tok) {
    token->ty = ty;
    token->loc = self->f->pos_offset + self->pos;
    token->len = end_pos - self->pos;
    token->value = &self->f->source.data[self->pos];
    self->pos = end_pos;
}

fn file_lexer_handle_end_of_file(self: FileLexer*, token: Token*, cur_pos: i64) {
    if (self->the_lexer != nullptr) {
        lexer_end_source_file(cast<Lexer*>(self->the_lexer), token);
    } else {
        file_lexer_construct_token(self, token, cur_pos, TOK_EOF);
    }
}

fn file_lexer_read_to_whitespace(self: FileLexer*, out: Str*) {
    out->data = &self->f->source.data[self->pos];
    out->len = self->pos;
    while (!isspace(self->f->source.data[self->pos])) self->pos = self->pos + 1;
    out->len = self->pos - out->len;
}

fn file_lexer_read_to_end_of_line(self: FileLexer*, out: Str*) {
    out->data = &self->f->source.data[self->pos];
    out->len = self->pos;
    let end_pos: i64;
    while (true) {
        if (self->f->source.data[self->pos] == '\n') {
            end_pos = self->pos;
            self->pos = self->pos + 1;
            if (self->f->source.data[self->pos] == '\r') self->pos = self->pos + 1;
            break;
        }
        if (self->f->source.data[self->pos] == '\r') {
            end_pos = self->pos;
            self->pos = self->pos + 1;
            if (self->f->source.data[self->pos] == '\n') self->pos = self->pos + 1;
            break;
        }
        self->pos = self->pos + 1;
    }
    out->len = end_pos - out->len;
}

fn file_lexer_handle_directive(self: FileLexer*, token: Token*) {
    if (self->the_lexer != nullptr) {
        lexer_handle_directive(cast<Lexer*>(self->the_lexer), token);
    } else {
        file_lexer_construct_token(self, token, self->pos + 1, TOK_EOF);
    }
}

fn ident_continue(c: i8) -> bool {
    if (c >= 'a') {
        if (c <= 'z') return true;
    }
    if (c >= 'A') {
        if (c <= 'Z') return true;
    }
    if (c >= '0') {
        if (c <= '9') return true;
    }
    return c == '_';
}

fn file_lexer_lex_ident(self: FileLexer*, token: Token*, cur_pos: i64) {
    let c: i8;
    c = self->f->source.data[cur_pos];
    while (ident_continue(c)) {
        cur_pos += 1;
        c = self->f->source.data[cur_pos];
    }
    let ii: IdentInfo*;
    ii = ident_info_find(&self->f->source.data[self->pos], cur_pos - self->pos);
    if (self->the_lexer != nullptr) if (ident_info_needs_handling(ii)) {
        lexer_handle_ident(cast<Lexer*>(self->the_lexer), token, ii);
    }
    file_lexer_construct_token(self, token, cur_pos, ii->ty);
    token->value = ii;
}

fn file_lexer_lex_number(self: FileLexer*, token: Token*, cur_pos: i64) {
    let c: i8;
    while (true) {
        c = self->f->source.data[cur_pos];
        if (c == 'e') {
            if (self->f->source.data[cur_pos + 1] == '+') {
                cur_pos += 2;
                continue;
            }
            if (self->f->source.data[cur_pos + 1] == '-') {
                cur_pos += 2;
                continue;
            }
        }
        if (c == '\'') {
            if (ident_continue(self->f->source.data[cur_pos + 1])) {
                cur_pos += 2;
                continue;
            }
        }
        if (ident_continue(c)) {
            cur_pos += 1;
            continue;
        }
        if (c == '.') {
            cur_pos += 1;
            continue;
        }
        break;
    }
    file_lexer_construct_token(self, token, cur_pos, TOK_NUM);
}

fn file_lexer_skip_to_end_of_line_comment(self: FileLexer*, cur_pos: i64) -> i64 {
    let c: i8;
    while (true) {
        c = self->f->source.data[cur_pos];
        if (c == '\0') return cur_pos;
        if (c == '\n') return cur_pos;
        if (c == '\r') return cur_pos;
        cur_pos += 1;
    }
}

fn file_lexer_skip_to_end_of_multiline_comment(self: FileLexer*, cur_pos: i64) -> i64 {
    let c: i8;
    while (true) {
        c = self->f->source.data[cur_pos];
        if (c == '\0') {
            if (cur_pos + 1 != self->f->source.len) {
                diag(self->f->pos_offset + cur_pos, "NULL in file", DIAG_WARNING);
                cur_pos += 1;
                continue;
            }
            diag(self->f->pos_offset + cur_pos, "unterminated multiline comment.", DIAG_ERROR);
            return cur_pos;
        } else if (c == '*') {
            if (self->f->source.data[cur_pos + 1] == '/') return cur_pos + 2;
        }
        cur_pos += 1;
    }
}

fn file_lexer_lex_char_literal(self: FileLexer*, token: Token*, cur_pos: i64) {
    let c: i8;
    c = self->f->source.data[cur_pos];
    while (c != '\'') {
        if (c == '\\') cur_pos += 1;
        cur_pos += 1;
        c = self->f->source.data[cur_pos];
    }
    file_lexer_construct_token(self, token, cur_pos + 1, TOK_CHR);
}

fn file_lexer_lex_str_literal(self: FileLexer*, token: Token*, cur_pos: i64) {
    let c: i8;
    c = self->f->source.data[cur_pos];
    while (c != '"') {
        if (c == '\\') cur_pos += 1;
        cur_pos += 1;
        c = self->f->source.data[cur_pos];
    }
    file_lexer_construct_token(self, token, cur_pos + 1, TOK_STR);
}

fn file_lexer_lex_internal(self: FileLexer*, token: Token*) {
    let c: i8;
    let cur_pos: i64;
    while (isspace(self->f->source.data[self->pos])) self->pos = self->pos + 1;
    c = self->f->source.data[self->pos];
    cur_pos = self->pos + 1;
    if (c == '\0') {
        if (cur_pos == self->f->source.len) file_lexer_handle_end_of_file(self, token, cur_pos);
        else {
            diag(self->pos + self->f->pos_offset, "NULL in file", DIAG_WARNING);
            self->pos = cur_pos;
            file_lexer_lex_internal(self, token);
        }
        return;
    }
    if (c == '#') {
        token->loc = self->f->pos_offset + self->pos;
        self->pos = self->pos + 1;
        file_lexer_handle_directive(self, token);
        return;
    }
    if (c <= '9') {
        if (c >= '0') {
            file_lexer_lex_number(self, token, cur_pos);
            return;
        }
    }
    if (c <= 'z') {
        if (c >= 'a') {
            file_lexer_lex_ident(self, token, cur_pos);
            return;
        }
    }
    if (c <= 'Z') {
        if (c >= 'A') {
            file_lexer_lex_ident(self, token, cur_pos);
            return;
        }
    }
    if (c == '_') {
        file_lexer_lex_ident(self, token, cur_pos);
        return;
    }
    if (c == '(') {
        file_lexer_construct_token(self, token, cur_pos, TOK_LPAREN);
        return;
    }
    if (c == ')') {
        file_lexer_construct_token(self, token, cur_pos, TOK_RPAREN);
        return;
    }
    if (c == '{') {
        file_lexer_construct_token(self, token, cur_pos, TOK_LBRACE);
        return;
    }
    if (c == '}') {
        file_lexer_construct_token(self, token, cur_pos, TOK_RBRACE);
        return;
    }
    if (c == '[') {
        file_lexer_construct_token(self, token, cur_pos, TOK_LSQUARE);
        return;
    }
    if (c == ']') {
        file_lexer_construct_token(self, token, cur_pos, TOK_RSQUARE);
        return;
    }
    if (c == ';') {
        file_lexer_construct_token(self, token, cur_pos, TOK_SEMI);
        return;
    }
    if (c == ':') {
        file_lexer_construct_token(self, token, cur_pos, TOK_COLON);
        return;
    }
    if (c == ',') {
        file_lexer_construct_token(self, token, cur_pos, TOK_COMMA);
        return;
    }
    if (c == '?') {
        file_lexer_construct_token(self, token, cur_pos, TOK_QUESTION);
        return;
    }
    if (c == '~') {
        file_lexer_construct_token(self, token, cur_pos, TOK_TILDE);
        return;
    }
    if (c == '<') {
        c = self->f->source.data[cur_pos];
        if (c == '<') {
            c = self->f->source.data[cur_pos + 1];
            if (c == '=') file_lexer_construct_token(self, token, cur_pos + 2, TOK_LESSLESSEQUAL);
            else file_lexer_construct_token(self, token, cur_pos + 1, TOK_LESSLESS);
        }
        else if (c == '=') file_lexer_construct_token(self, token, cur_pos + 1, TOK_LESSEQUAL);
        else file_lexer_construct_token(self, token, cur_pos, TOK_LESS);
        return;
    }
    if (c == '>') {
        c = self->f->source.data[cur_pos];
        if (c == '>') {
            c = self->f->source.data[cur_pos + 1];
            if (c == '=') file_lexer_construct_token(self, token, cur_pos + 2, TOK_GREATERGREATEREQUAL);
            else file_lexer_construct_token(self, token, cur_pos + 1, TOK_GREATERGREATER);
        }
        else if (c == '=') file_lexer_construct_token(self, token, cur_pos + 1, TOK_GREATEREQUAL);
        else file_lexer_construct_token(self, token, cur_pos, TOK_GREATER);
        return;
    }
    if (c == '=') {
        c = self->f->source.data[cur_pos];
        if (c == '=') file_lexer_construct_token(self, token, cur_pos + 1, TOK_EQUALEQUAL);
        else file_lexer_construct_token(self, token, cur_pos, TOK_EQUAL);
        return;
    }
    if (c == '+') {
        c = self->f->source.data[cur_pos];
        if (c == '+') file_lexer_construct_token(self, token, cur_pos + 1, TOK_PLUSPLUS);
        else if (c == '=') file_lexer_construct_token(self, token, cur_pos + 1, TOK_PLUSEQUAL);
        else file_lexer_construct_token(self, token, cur_pos, TOK_PLUS);
        return;
    }
    if (c == '-') {
        c = self->f->source.data[cur_pos];
        if (c == '-') file_lexer_construct_token(self, token, cur_pos + 1, TOK_MINUSMINUS);
        else if (c == '=') file_lexer_construct_token(self, token, cur_pos + 1, TOK_MINUSEQUAL);
        else if (c == '>') file_lexer_construct_token(self, token, cur_pos + 1, TOK_ARROW);
        else file_lexer_construct_token(self, token, cur_pos, TOK_MINUS);
        return;
    }
    if (c == '*') {
        c = self->f->source.data[cur_pos];
        if (c == '=') file_lexer_construct_token(self, token, cur_pos + 1, TOK_STAREQUAL);
        else file_lexer_construct_token(self, token, cur_pos, TOK_STAR);
        return;
    }
    if (c == '%') {
        c = self->f->source.data[cur_pos];
        if (c == '=') file_lexer_construct_token(self, token, cur_pos + 1, TOK_PERCENTEQUAL);
        else file_lexer_construct_token(self, token, cur_pos, TOK_PERCENT);
        return;
    }
    if (c == '!') {
        c = self->f->source.data[cur_pos];
        if (c == '=') file_lexer_construct_token(self, token, cur_pos + 1, TOK_EXCLAIMEQUAL);
        else file_lexer_construct_token(self, token, cur_pos, TOK_EXCLAIM);
        return;
    }
    if (c == '^') {
        c = self->f->source.data[cur_pos];
        if (c == '=') file_lexer_construct_token(self, token, cur_pos + 1, TOK_CARETEQUAL);
        else file_lexer_construct_token(self, token, cur_pos, TOK_CARET);
        return;
    }
    if (c == '&') {
        c = self->f->source.data[cur_pos];
        if (c == '&') file_lexer_construct_token(self, token, cur_pos + 1, TOK_AMPAMP);
        else if (c == '=') file_lexer_construct_token(self, token, cur_pos + 1, TOK_AMPEQUAL);
        else file_lexer_construct_token(self, token, cur_pos, TOK_AMP);
        return;
    }
    if (c == '|') {
        c = self->f->source.data[cur_pos];
        if (c == '|') file_lexer_construct_token(self, token, cur_pos + 1, TOK_PIPEPIPE);
        else if (c == '=') file_lexer_construct_token(self, token, cur_pos + 1, TOK_PIPEEQUAL);
        else file_lexer_construct_token(self, token, cur_pos, TOK_PIPE);
        return;
    }
    if (c == '/') {
        c = self->f->source.data[cur_pos];
        if (c == '/') {
            self->pos = file_lexer_skip_to_end_of_line_comment(self, cur_pos + 1);
            file_lexer_lex_internal(self, token);
        } else if (c == '*') {
            self->pos = file_lexer_skip_to_end_of_multiline_comment(self, cur_pos + 1);
            file_lexer_lex_internal(self, token);
        }
        else if (c == '=') file_lexer_construct_token(self, token, cur_pos + 1, TOK_SLASHEQUAL);
        else file_lexer_construct_token(self, token, cur_pos, TOK_SLASH);
        return;
    }
    if (c == '.') {
        c = self->f->source.data[cur_pos];
        if (c <= '9') {
            if (c >= '0') {
                file_lexer_lex_number(self, token, cur_pos + 1);
                return;
            }
        }
        if (c == '.') {
            if (self->f->source.data[cur_pos + 1] == '.') {
                file_lexer_construct_token(self, token, cur_pos + 2, TOK_ELLIPSIS);
                return;
            }
        }
        file_lexer_construct_token(self, token, cur_pos, TOK_PERIOD);
        return;
    }
    if (c == '\'') {
        file_lexer_lex_char_literal(self, token, cur_pos);
        return;
    }
    if (c == '"') {
        file_lexer_lex_str_literal(self, token, cur_pos);
        return;
    }
    let diag_msg: String;
    string_init(&diag_msg);
    string_format(&diag_msg, "Unknown character '%c' in source file", c);
    diag(self->pos + self->f->pos_offset, diag_msg.inner.data, DIAG_ERROR);
    string_destroy(&diag_msg);
    self->pos = cur_pos;
    file_lexer_lex_internal(self, token);
}

fn file_lexer_lex(self: FileLexer*) -> Token* {
    let out: Token*;
    out = malloc(sizeof(Token));
    file_lexer_lex_internal(self, out);
    return out;
}
